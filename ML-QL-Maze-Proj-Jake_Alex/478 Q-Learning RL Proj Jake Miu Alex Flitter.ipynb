{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23392609",
   "metadata": {},
   "source": [
    "# Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc84dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from stable-baselines3[extra]) (1.20.3)\n",
      "Collecting torch>=1.8.1\n",
      "  Downloading torch-1.11.0-cp39-cp39-win_amd64.whl (157.9 MB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from stable-baselines3[extra]) (3.4.3)\n",
      "Collecting gym==0.21\n",
      "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
      "Requirement already satisfied: pandas in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from stable-baselines3[extra]) (1.3.4)\n",
      "Collecting ale-py~=0.7.4\n",
      "  Downloading ale_py-0.7.5-cp39-cp39-win_amd64.whl (935 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from stable-baselines3[extra]) (5.8.0)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting autorom[accept-rom-license]~=0.4.2\n",
      "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "Requirement already satisfied: pillow in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from stable-baselines3[extra]) (8.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from ale-py~=0.7.4->stable-baselines3[extra]) (4.11.3)\n",
      "Collecting importlib-resources\n",
      "  Downloading importlib_resources-5.7.1-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.62.3)\n",
      "Requirement already satisfied: requests in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.26.0)\n",
      "Requirement already satisfied: click in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.0.3)\n",
      "Collecting AutoROM.accept-rom-license\n",
      "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from importlib-metadata>=4.10.0->ale-py~=0.7.4->stable-baselines3[extra]) (3.6.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-win_amd64.whl (3.4 MB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.5-py2.py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.0.2)\n",
      "Collecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.20.0-cp39-cp39-win_amd64.whl (904 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (58.0.4)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: six in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from absl-py>=0.4->tensorboard>=2.2.0->stable-baselines3[extra]) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.7)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from torch>=1.8.1->stable-baselines3[extra]) (3.10.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\owner\\downloads\\new folder\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2021.3)\n",
      "Building wheels for collected packages: gym, AutoROM.accept-rom-license\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616823 sha256=47f0270894453609edfb214750c602df168f0a6fa1c78153c6def8771af96061\n",
      "  Stored in directory: c:\\users\\owner\\appdata\\local\\pip\\cache\\wheels\\b3\\50\\6c\\0a82c1358b4da2dbd9c1bb17e0f89467db32812ab236dbf6d5\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517): started\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517): finished with status 'done'\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=446464 sha256=59ba614720dfe67a04aa500fa9810636e5159e70ec7684b50182524f4a8780b6\n",
      "  Stored in directory: c:\\users\\owner\\appdata\\local\\pip\\cache\\wheels\\2b\\03\\e4\\8b662e95b85786a03898fca125d5a9e3fe49337b1eba8fddd2\n",
      "Successfully built gym AutoROM.accept-rom-license\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, torch, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, importlib-resources, gym, grpcio, google-auth-oauthlib, AutoROM.accept-rom-license, autorom, absl-py, tensorboard, stable-baselines3, opencv-python, ale-py\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.23.1\n",
      "    Uninstalling gym-0.23.1:\n",
      "      Successfully uninstalled gym-0.23.1\n",
      "Successfully installed AutoROM.accept-rom-license-0.4.2 absl-py-1.0.0 ale-py-0.7.5 autorom-0.4.2 cachetools-5.0.0 google-auth-2.6.5 google-auth-oauthlib-0.4.6 grpcio-1.44.0 gym-0.21.0 importlib-resources-5.7.1 markdown-3.3.6 oauthlib-3.2.0 opencv-python-4.5.5.64 protobuf-3.20.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 stable-baselines3-1.5.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torch-1.11.0\n"
     ]
    }
   ],
   "source": [
    "# install modules stable-baselines3 includes gym\n",
    "!pip install stable-baselines3[extra] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35752097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow gym keras keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f341c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN = Deep-Q-Network - maximize bellman equation, MLP Policy for model\n",
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8dcc7f",
   "metadata": {},
   "source": [
    "# Building the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04089410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for maze env where agent will learn\n",
    "class MazeEnv(Env):\n",
    "    \n",
    "    # maze member_variables & action / observation space\n",
    "    def __init__(self, DIM_COL_ROW, STARTING_CELL, WALLS):\n",
    "        # declare num_col & num_row; boards are square\n",
    "        self.dim_row_col = DIM_COL_ROW\n",
    "        # declare starting cell\n",
    "        self.starting_cell = STARTING_CELL\n",
    "        # actions we can take, up, right, down, left ; NESW\n",
    "        self.action_space = Discrete(4) # 0,1,2,3\n",
    "        # observation \n",
    "        # option1 - discrete(36) w/ % to make 6x6 grid\n",
    "        # option2 - Tuple((Discrete(DIM_COL_ROW), Discrete(DIM_COL_ROW))\n",
    "        # option3 - box w/ np.arrays made discrete elements\n",
    "        # taking option 3 bc tuple DNE\n",
    "        self.observation_space = Box(np.array((0,0), dtype=int), np.array((DIM_COL_ROW-1,DIM_COL_ROW-1)), dtype=np.int64)\n",
    "        # self.observation_space = Tuple((Discrete(DIM_COL_ROW), Discrete(DIM_COL_ROW)))\n",
    "        # set starting cell - note self.state updates per step\n",
    "        # self.state = np.array(STARTING_CELL, dtype=np.int64)\n",
    "        self.state = None\n",
    "        # self.state = STARTING_CELL\n",
    "        # set max_steps to prevent infinite searching in maze\n",
    "        self.max_steps = 100000 # 1000 baseline, will change\n",
    "        # set current step for iterating action steps\n",
    "        self.current_step = 0\n",
    "        # set value for cell in maze that ends episode\n",
    "        self.end_cell = np.array((DIM_COL_ROW-1,DIM_COL_ROW-1),dtype=np.int64)\n",
    "        # self.end_cell = (DIM_COL_ROW-1,DIM_COL_ROW-1)\n",
    "        # set episode termination variable to false\n",
    "        self.episode_terminated = False\n",
    "        # set walls for maze below\n",
    "        self.Walls = WALLS\n",
    "        \n",
    "    # note - impossible move below pass increments; optimize by logic on step\n",
    "    # how about step incrementer in else (non-pass steps)\n",
    "        \n",
    "    # moves agent around env; how actions change states\n",
    "    def step(self, action):\n",
    "        # added to test assertion error fix\n",
    "        \"\"\"\n",
    "        if not (self.state):\n",
    "            self.state = np.array(self.starting_cell, dtype=np.int64)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _ = self.state[0]\n",
    "        except ValueError:\n",
    "            #self.state = np.array(self.starting_cell, dtype=np.int64)\n",
    "            self.state = self.starting_cell\n",
    "        # action discrete values defined below\n",
    "        # 0 is down \n",
    "        # 1 is left\n",
    "        # 2 is up\n",
    "        # 3 is right\n",
    "        # take action & change state cell; passes prevent action in else\n",
    "        # if action is down or up\n",
    "        if (action == 0 or action == 2):\n",
    "            # if wall DNE\n",
    "            if (self.Walls[2*self.state[0]+1, self.state[1]+ (action//2)] == 0):\n",
    "                # move to new state\n",
    "                self.state = (self.state[0], self.state[1] + (action - 1))\n",
    "                # increment steps\n",
    "                self.current_step += 1    \n",
    "            # if wall exists\n",
    "            else:\n",
    "                pass\n",
    "        # else action is left or right\n",
    "        else:\n",
    "            # if wall DNE\n",
    "            if (self.Walls[2*(self.state[0] + (action//2)) , self.state[1]] == 0):\n",
    "                # move to new state\n",
    "                self.state = (self.state[0] + (action - 2), self.state[1])\n",
    "                # increment steps\n",
    "                self.current_step += 1\n",
    "            # if wall exists\n",
    "            else:\n",
    "                pass       \n",
    "        \n",
    "        # calculate reward & check if at end-condition\n",
    "        #if (self.state == self.end_cell):\n",
    "        if (np.array_equal(self.state,self.end_cell)):    \n",
    "            self.episode_terminated = True\n",
    "            reward = 100\n",
    "        else:\n",
    "            # incentive to keep moving; reach end quickly\n",
    "            reward = -1/(self.dim_row_col*self.dim_row_col)\n",
    "            \n",
    "        # end-condition w/ out reward is too many steps taken\n",
    "        if (self.current_step >= self.max_steps):\n",
    "            self.episode_terminated = True\n",
    "            \n",
    "        # info {} must be returned for step() for Env class; dk why\n",
    "        info = {}\n",
    "        \n",
    "        # return step information\n",
    "        return np.array(self.state, dtype=np.int64), reward, self.episode_terminated, info\n",
    "                \n",
    "    # implements visuals of learning process\n",
    "    # COULD USE PYGAME ??? - See mattchan maze_view_2d.py\n",
    "    def render(self):\n",
    "        # implement viz\n",
    "        pass\n",
    "    \n",
    "    # reset sets env's params to starting values\n",
    "    def reset(self):\n",
    "        # reset state to starting cell\n",
    "        self.state = np.array(self.starting_cell, dtype=np.int64)\n",
    "        # reset episode_terminated to episode running\n",
    "        self.episode_terminated = False\n",
    "        # reset current step to no steps taken\n",
    "        self.current_step = 0\n",
    "        # return state to exploit; model.predict(env.reset()) in test model\n",
    "        #return np.array(self.state, dtype=np.int64)\n",
    "        return self.state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca7c434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dimensions of square maze & starting cell in maze\n",
    "DIM_COL_ROW = 6\n",
    "STARTING_CELL = (0,0)\n",
    "# walls is subject to dim; hardcode changes on input\n",
    "# even x indices are vert walls; up & down actions permittable if val = 0\n",
    "# odd x indices are horz walls; right and left actions permittable if val = 0\n",
    "# end-points of x indices are the edges of the grid\n",
    "# val = 2 => noise in wall grid (wall N/A; neither T/F)\n",
    "# specifically, val = 2 => vert & edges-grid top of grid\n",
    "# for Walls, each row is a set of edges-grid + vert + horz  borders\n",
    "# for Walls, num_col = dim_col_row+1; border numbers\n",
    "'''\n",
    "WALLS = np.array([\n",
    "                [1,1,1,1,1,1,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [0,0,0,0,0,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [0,0,0,0,0,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [0,0,0,0,0,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [0,0,0,0,0,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [0,0,0,0,0,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [1,1,1,1,1,1,2]\n",
    "                ])\n",
    "'''\n",
    "WALLS = np.array([\n",
    "                [1,1,1,1,1,1,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [1,0,1,0,1,0,2],\n",
    "                [1,1,1,1,1,1,1],\n",
    "                [0,0,0,0,0,0,2],\n",
    "                [1,0,1,1,1,1,1],\n",
    "                [1,1,0,0,1,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [1,1,1,0,1,1,2],\n",
    "                [1,0,0,0,1,1,1],\n",
    "                [0,1,1,1,0,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [1,1,1,1,1,1,2]\n",
    "                ])\n",
    "\n",
    "\n",
    "# declare environment\n",
    "env = MazeEnv(DIM_COL_ROW, STARTING_CELL, WALLS)\n",
    "# ensure env functions with stable_baselines well\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17607857",
   "metadata": {},
   "source": [
    "# Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18cf2027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:63.166666666665876 Steps:1326\n",
      "Episode:2 Score:65.74999999999929 Steps:1233\n",
      "Episode:3 Score:86.55555555555543 Steps:484\n",
      "Episode:4 Score:93.08333333333336 Steps:248\n",
      "Episode:5 Score:98.11111111111111 Steps:67\n",
      "Episode:6 Score:94.0277777777778 Steps:214\n",
      "Episode:7 Score:76.33333333333292 Steps:852\n",
      "Episode:8 Score:42.58333333333196 Steps:2067\n",
      "Episode:9 Score:93.22222222222224 Steps:243\n",
      "Episode:10 Score:88.49999999999993 Steps:414\n",
      "Episode:11 Score:74.69444444444397 Steps:911\n",
      "Episode:12 Score:95.83333333333334 Steps:149\n",
      "Episode:13 Score:94.97222222222223 Steps:180\n",
      "Episode:14 Score:67.63888888888823 Steps:1165\n",
      "Episode:15 Score:70.88888888888832 Steps:1048\n",
      "Episode:16 Score:68.24999999999935 Steps:1143\n",
      "Episode:17 Score:43.416666666665314 Steps:2037\n",
      "Episode:18 Score:97.5 Steps:90\n",
      "Episode:19 Score:44.91666666666536 Steps:1983\n",
      "Episode:20 Score:67.61111111111045 Steps:1166\n",
      "Episode:21 Score:83.88888888888869 Steps:580\n",
      "Episode:22 Score:81.47222222222194 Steps:667\n",
      "Episode:23 Score:97.08333333333334 Steps:104\n",
      "Episode:24 Score:70.2499999999994 Steps:1071\n",
      "Episode:25 Score:87.38888888888879 Steps:454\n",
      "Episode:26 Score:92.30555555555557 Steps:276\n",
      "Episode:27 Score:-24.499999999987807 Steps:4481\n",
      "Episode:28 Score:67.49999999999933 Steps:1170\n",
      "Episode:29 Score:97.16666666666667 Steps:101\n",
      "Episode:30 Score:92.33333333333336 Steps:275\n",
      "Episode:31 Score:92.58333333333336 Steps:266\n",
      "Episode:32 Score:10.944444444448578 Steps:3205\n",
      "Episode:33 Score:69.4722222222216 Steps:1099\n",
      "Episode:34 Score:12.861111111114809 Steps:3136\n",
      "Episode:35 Score:88.61111111111104 Steps:410\n",
      "Episode:36 Score:25.861111111111853 Steps:2668\n",
      "Episode:37 Score:0.5555555555620515 Steps:3579\n",
      "Episode:38 Score:77.61111111111073 Steps:806\n",
      "Episode:39 Score:90.19444444444441 Steps:353\n",
      "Episode:40 Score:62.94444444444365 Steps:1334\n",
      "Episode:41 Score:-79.72222222219747 Steps:6469\n",
      "Episode:42 Score:92.72222222222224 Steps:261\n",
      "Episode:43 Score:92.44444444444447 Steps:271\n",
      "Episode:44 Score:96.75000000000001 Steps:116\n",
      "Episode:45 Score:62.777777777776976 Steps:1340\n",
      "Episode:46 Score:60.638888888888026 Steps:1417\n",
      "Episode:47 Score:76.91666666666626 Steps:831\n",
      "Episode:48 Score:96.44444444444446 Steps:127\n",
      "Episode:49 Score:64.52777777777703 Steps:1277\n",
      "Episode:50 Score:75.36111111111066 Steps:887\n",
      "--------------------------------------------------\n",
      "Average Score:68.84888888888959 Average Steps:1121.02\n"
     ]
    }
   ],
   "source": [
    "episodes = 50\n",
    "average_score = 0\n",
    "average_steps = 0\n",
    "# iterate through simulated episodes of the env with random actions\n",
    "for episode in range(1, episodes+1):\n",
    "    # make state at starting cell\n",
    "    state = env.reset()\n",
    "    # reset boolean for simulation\n",
    "    done = False\n",
    "    # score is metric for rewards\n",
    "    score = 0 \n",
    "    # logic for scores\n",
    "    # simulate a singular episode with random action\n",
    "    while not done:\n",
    "        # render env\n",
    "        env.render()\n",
    "        # random actions hence .sample()\n",
    "        action = env.action_space.sample()\n",
    "        # step from state with action & capture step info\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        # increment reward metric\n",
    "        score+=reward\n",
    "    # display simulation results\n",
    "    print('Episode:{} Score:{} Steps:{}'.format(episode, score, int((100-score)*(DIM_COL_ROW*DIM_COL_ROW))))\n",
    "    # update average_score & average_steps\n",
    "    average_score += score\n",
    "    average_steps += int((100-score)*(DIM_COL_ROW*DIM_COL_ROW))\n",
    "# display simulation average score & steps\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Average Score:{} Average Steps:{}\".format(average_score/episodes, average_steps/episodes))\n",
    "# env.close() - needed when render implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95239d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
