{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23392609",
   "metadata": {},
   "source": [
    "# Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4fc84dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in t:\\installs\\anaconda_location\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: matplotlib in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (3.4.3)\n",
      "Requirement already satisfied: pandas in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (1.3.4)\n",
      "Requirement already satisfied: gym==0.21 in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (0.21.0)\n",
      "Requirement already satisfied: numpy in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (1.20.3)\n",
      "Requirement already satisfied: torch>=1.8.1 in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (1.11.0)\n",
      "Requirement already satisfied: cloudpickle in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: pillow in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (8.4.0)\n",
      "Requirement already satisfied: psutil in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (5.8.0)\n",
      "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: opencv-python in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (4.5.5.64)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (2.8.0)\n",
      "Requirement already satisfied: ale-py~=0.7.4 in t:\\installs\\anaconda_location\\lib\\site-packages (from stable-baselines3[extra]) (0.7.4)\n",
      "Requirement already satisfied: importlib-metadata>=4.10.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from ale-py~=0.7.4->stable-baselines3[extra]) (4.11.3)\n",
      "Requirement already satisfied: importlib-resources in t:\\installs\\anaconda_location\\lib\\site-packages (from ale-py~=0.7.4->stable-baselines3[extra]) (5.7.0)\n",
      "Requirement already satisfied: requests in t:\\installs\\anaconda_location\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.26.0)\n",
      "Requirement already satisfied: tqdm in t:\\installs\\anaconda_location\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (4.62.3)\n",
      "Requirement already satisfied: click in t:\\installs\\anaconda_location\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (8.0.3)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in t:\\installs\\anaconda_location\\lib\\site-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in t:\\installs\\anaconda_location\\lib\\site-packages (from importlib-metadata>=4.10.0->ale-py~=0.7.4->stable-baselines3[extra]) (3.6.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (58.0.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.0.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.20.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.37.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.6.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.44.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in t:\\installs\\anaconda_location\\lib\\site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: six in t:\\installs\\anaconda_location\\lib\\site-packages (from absl-py>=0.4->tensorboard>=2.2.0->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in t:\\installs\\anaconda_location\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in t:\\installs\\anaconda_location\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in t:\\installs\\anaconda_location\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in t:\\installs\\anaconda_location\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in t:\\installs\\anaconda_location\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in t:\\installs\\anaconda_location\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in t:\\installs\\anaconda_location\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions in t:\\installs\\anaconda_location\\lib\\site-packages (from torch>=1.8.1->stable-baselines3[extra]) (3.10.0.2)\n",
      "Requirement already satisfied: colorama in t:\\installs\\anaconda_location\\lib\\site-packages (from click->autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]) (0.4.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in t:\\installs\\anaconda_location\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in t:\\installs\\anaconda_location\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in t:\\installs\\anaconda_location\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in t:\\installs\\anaconda_location\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in t:\\installs\\anaconda_location\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2021.3)\n"
     ]
    }
   ],
   "source": [
    "# install modules stable-baselines3 includes gym\n",
    "!pip install stable-baselines3[extra] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35752097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow gym keras keras-rl2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f341c988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN = Deep-Q-Network - maximize bellman equation, MLP Policy for model\n",
    "import gym \n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8dcc7f",
   "metadata": {},
   "source": [
    "# Building the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04089410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for maze env where agent will learn\n",
    "class MazeEnv(Env):\n",
    "    \n",
    "    # maze member_variables & action / observation space\n",
    "    def __init__(self, DIM_COL_ROW, STARTING_CELL, WALLS):\n",
    "        # declare num_col & num_row; boards are square\n",
    "        self.dim_row_col = DIM_COL_ROW\n",
    "        # declare starting cell\n",
    "        self.starting_cell = STARTING_CELL\n",
    "        # actions we can take, up, right, down, left ; NESW\n",
    "        self.action_space = Discrete(4) # 0,1,2,3\n",
    "        # observation \n",
    "        # option1 - discrete(36) w/ % to make 6x6 grid\n",
    "        # option2 - Tuple((Discrete(DIM_COL_ROW), Discrete(DIM_COL_ROW))\n",
    "        # option3 - box w/ np.arrays made discrete elements\n",
    "        # taking option 3 bc tuple DNE\n",
    "        self.observation_space = Box(np.array((0,0), dtype=int), np.array((DIM_COL_ROW-1,DIM_COL_ROW-1)), dtype=np.int64)\n",
    "        # self.observation_space = Tuple((Discrete(DIM_COL_ROW), Discrete(DIM_COL_ROW)))\n",
    "        # set starting cell - note self.state updates per step\n",
    "        # self.state = np.array(STARTING_CELL, dtype=np.int64)\n",
    "        self.state = None\n",
    "        # self.state = STARTING_CELL\n",
    "        # set max_steps to prevent infinite searching in maze\n",
    "        self.max_steps = 1000 # 1000 baseline, will change\n",
    "        # set current step for iterating action steps\n",
    "        self.current_step = 0\n",
    "        # set value for cell in maze that ends episode\n",
    "        self.end_cell = np.array((DIM_COL_ROW-1,DIM_COL_ROW-1),dtype=np.int64)\n",
    "        # self.end_cell = (DIM_COL_ROW-1,DIM_COL_ROW-1)\n",
    "        # set episode termination variable to false\n",
    "        self.episode_terminated = False\n",
    "        # set walls for maze below\n",
    "        self.Walls = WALLS\n",
    "        \n",
    "    # note - impossible move below pass increments; optimize by logic on step\n",
    "    # how about step incrementer in else (non-pass steps)\n",
    "        \n",
    "    # moves agent around env; how actions change states\n",
    "    def step(self, action):\n",
    "        # added to test assertion error fix\n",
    "        \"\"\"\n",
    "        if not (self.state):\n",
    "            self.state = np.array(self.starting_cell, dtype=np.int64)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            _ = self.state[0]\n",
    "        except ValueError:\n",
    "            #self.state = np.array(self.starting_cell, dtype=np.int64)\n",
    "            self.state = self.starting_cell\n",
    "        # action discrete values defined below\n",
    "        # 0 is down \n",
    "        # 1 is left\n",
    "        # 2 is up\n",
    "        # 3 is right\n",
    "        # take action & change state cell; passes prevent action in else\n",
    "        # if action is down or up\n",
    "        if (action == 0 or action == 2):\n",
    "            # if wall DNE\n",
    "            if (self.Walls[2*self.state[0]+1, self.state[0]+ (action//2)] == 0):\n",
    "                # move to new state\n",
    "                self.state = (self.state[0] + (action - 1), self.state[1])\n",
    "                # increment steps\n",
    "                self.current_step += 1    \n",
    "            # if wall exists\n",
    "            else:\n",
    "                pass\n",
    "        # else action is left or right\n",
    "        else:\n",
    "            # if wall DNE\n",
    "            if (self.Walls[2*(self.state[0] + (action//2)) , self.state[1]] == 0):\n",
    "                # move to new state\n",
    "                self.state = (self.state[0], self.state[1] + (action - 2))\n",
    "                # increment steps\n",
    "                self.current_step += 1\n",
    "            # if wall exists\n",
    "            else:\n",
    "                pass       \n",
    "        \n",
    "        # calculate reward & check if at end-condition\n",
    "        #if (self.state == self.end_cell):\n",
    "        if (np.array_equal(self.state,self.end_cell)):    \n",
    "            self.episode_terminated = True\n",
    "            reward = 100\n",
    "        else:\n",
    "            # incentive to keep moving; reach end quickly\n",
    "            reward = -1/(self.dim_row_col*self.dim_row_col)\n",
    "            \n",
    "        # end-condition w/ out reward is too many steps taken\n",
    "        if (self.current_step >= self.max_steps):\n",
    "            self.episode_terminated = True\n",
    "            \n",
    "        # info {} must be returned for step() for Env class; dk why\n",
    "        info = {}\n",
    "        \n",
    "        # return step information\n",
    "        return np.array(self.state, dtype=np.int64), reward, self.episode_terminated, info\n",
    "                \n",
    "    # implements visuals of learning process\n",
    "    # COULD USE PYGAME ??? - See mattchan maze_view_2d.py\n",
    "    def render(self):\n",
    "        # implement viz\n",
    "        pass\n",
    "    \n",
    "    # reset sets env's params to starting values\n",
    "    def reset(self):\n",
    "        # reset state to starting cell\n",
    "        self.state = np.array(self.starting_cell, dtype=np.int64)\n",
    "        # reset episode_terminated to episode running\n",
    "        self.episode_terminated = False\n",
    "        # reset current step to no steps taken\n",
    "        self.current_step = 0\n",
    "        # return state to exploit; model.predict(env.reset()) in test model\n",
    "        #return np.array(self.state, dtype=np.int64)\n",
    "        return self.state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ca7c434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dimensions of square maze & starting cell in maze\n",
    "DIM_COL_ROW = 6\n",
    "STARTING_CELL = (0,0)\n",
    "# walls is subject to dim; hardcode changes on input\n",
    "# even x indices are vert walls; up & down actions permittable if val = 0\n",
    "# odd x indices are horz walls; right and left actions permittable if val = 0\n",
    "# end-points of x indices are the edges of the grid\n",
    "# val = 2 => noise in wall grid (wall N/A; neither T/F)\n",
    "# specifically, val = 2 => vert & edges-grid top of grid\n",
    "# for Walls, each row is a set of edges-grid + vert + horz  borders\n",
    "# for Walls, num_col = dim_col_row+1; border numbers\n",
    "WALLS = np.array([\n",
    "                [1,1,1,1,1,1,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [1,0,1,0,1,0,2],\n",
    "                [1,1,1,1,1,1,1],\n",
    "                [0,0,0,0,0,0,2],\n",
    "                [1,0,1,1,1,1,1],\n",
    "                [1,1,0,0,1,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [1,1,1,0,1,1,2],\n",
    "                [1,0,0,0,1,1,1],\n",
    "                [0,1,1,1,0,0,2],\n",
    "                [1,0,0,0,0,0,1],\n",
    "                [1,1,1,1,1,1,2]\n",
    "                ])\n",
    "# declare environment\n",
    "env = MazeEnv(DIM_COL_ROW, STARTING_CELL, WALLS)\n",
    "# ensure env functions with stable_baselines well\n",
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17607857",
   "metadata": {},
   "source": [
    "# Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18cf2027",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5756/3883324722.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m# random actions hence .sample()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m# step from state with action & capture step info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mn_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 1\n",
    "average_score = 0\n",
    "average_steps = 0\n",
    "# iterate through simulated episodes of the env with random actions\n",
    "for episode in range(1, episodes+1):\n",
    "    # make state at starting cell\n",
    "    state = env.reset()\n",
    "    # reset boolean for simulation\n",
    "    done = False\n",
    "    # score is metric for rewards\n",
    "    score = 0 \n",
    "    # logic for scores\n",
    "    # simulate a singular episode with random action\n",
    "    while not done:\n",
    "        # render env\n",
    "        env.render()\n",
    "        # random actions hence .sample()\n",
    "        action = env.action_space.sample()\n",
    "        # step from state with action & capture step info\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        # increment reward metric\n",
    "        score+=reward\n",
    "    # display simulation results\n",
    "    print('Episode:{} Score:{} Steps:{}'.format(episode, score, int((100-score)*(DIM_COL_ROW*DIM_COL_ROW))))\n",
    "    # update average_score & average_steps\n",
    "    average_score += score\n",
    "    average_steps += int((100-score)*(DIM_COL_ROW*DIM_COL_ROW))\n",
    "# display simulation average score & steps\n",
    "print(\"--------------------------------------------------\")\n",
    "print(\"Average Score:{} Average Steps:{}\".format(average_score/episodes, average_steps/episodes))\n",
    "# env.close() - needed when render implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95239d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
